experiment_params:
#  dataset_root: &dataset_root "/storage/datasets/celeba_hq_256"
#  path: &path "/storage/experiments"
#  pretrained_ae_path: &pretrained_ae_path "/storage/experiments/remote/vq/VQVIC-40/checkpoint.ckpt"
  path: &path "/data/shared/svc/experiments"
  dataset_root: &dataset_root "/data/shared/svc/datasets/vimeo90k/vimeo_septuplet"
  pretrained_ae_path: &pretrained_ae_path "/data/shared/svc/pretrained/vq_vae/VQVIC-80/checkpoint.ckpt"
  pretrained_top_path: &pretrained_top_path "/data/shared/svc/pretrained/vq_vae/VQVIC-81/checkpoint.ckpt"
  dataloader_workers: &dataloader_workers 12
  image_resolution: &image_resolution (256, 256)

  gpu: &gpu 1

  lr: &lr 3e-4
  wd: &wd 1e-2
  epochs: &epochs 1000
  batch_size: &batch_size 12

  n_residual_blocks: &n_residual_blocks 3
  code_book_dim: &code_book_dim 64
  code_book_size: &code_book_size 512

  ema_decay: &vq_ema_decay 0.99
  commit_weight: &commit_weight 0.25

  lmbda: &lmbda 1


### Trainer
trainer: !Trainer
  deterministic: False
  benchmark: True
  gpus: `[gpu]`
  max_epochs: *epochs
  logger: !NeptuneLogger
    project: timeescaper/vq-vic
    log_model_checkpoints: True
    tags:
      - "compression"
      - "vimeo"
      - "bottom_rate"
  callbacks:
    - !ModelCheckpoint
      save_top_k: 1
      save_last: True
      every_n_epochs: 1
      monitor: "val_loss"
  check_val_every_n_epoch: 5
  log_every_n_steps: 1


### Datasets
train_dataset: &train_dataset !VimeoImagesDataset
  sequences_root: `f"{dataset_root}/sequences"`
  subset_list: `f"{dataset_root}/sep_trainlist.txt"`
  segment: (0, 10000)
  transform: !Compose
    transforms:
      - !CenterCrop
        size: *image_resolution
      - !ToTensor

val_dataset: &val_dataset !VimeoImagesDataset
  sequences_root: `f"{dataset_root}/sequences"`
  subset_list: `f"{dataset_root}/sep_testlist.txt"`
  segment: (0, 500)
  transform: !Compose
    transforms:
      - !CenterCrop
        size: *image_resolution
      - !ToTensor

train_dataloader: !DataLoader
  dataset: *train_dataset
  batch_size: *batch_size
  shuffle: true
  num_workers: *dataloader_workers

val_dataloader: !DataLoader
  dataset: *val_dataset
  batch_size: *batch_size
  shuffle: false
  num_workers: *dataloader_workers


# Model
encoder_bottom: &encoder_bottom !ConvEncoder
  channels: (64, 128)
  n_residual_blocks: *n_residual_blocks

encoder_top: &encoder_top !ConvEncoder
  channels: (128,)
  in_channels: 128
  n_residual_blocks: *n_residual_blocks

decoder_top: &decoder_top !ConvDecoder
  channels: `(code_book_dim,)`
  out_channels: *code_book_dim
  n_residual_blocks: *n_residual_blocks

decoder_bottom: &decoder_bottom !ConvDecoder
  channels: `(code_book_dim * 2, 64)`
  n_residual_blocks: *n_residual_blocks

ae_model_template: &ae_model_template !VectorQuantizedAE2
  encoder_bottom: *encoder_bottom
  decoder_bottom: *decoder_bottom
  encoder_top: *encoder_top
  decoder_top: *decoder_top
  code_book_dim: *code_book_dim
  code_book_size: *code_book_size
  decay: *vq_ema_decay

ae_model: &ae_model !pretrained
  model: *ae_model_template
  eval_mode: true
  freeze_model: true
  module_name: "_model._vq_ae"
  ckpt_path: *pretrained_ae_path

entropy_bottom: &entropy_bottom !PixelSNAIL
  input_mode: "indices"
  input_dim: *code_book_dim
  shape: (64, 64)
  n_class: *code_book_size
  channel: 256
  kernel_size: 5
  n_block: 4
  n_res_block: 4
  res_channel: 256
  dropout: 0.1
  attention: false
  n_cond_res_block: 3
  cond_res_channel: 256

entropy_top_template: &entropy_top_template !PixelSNAIL
  input_mode: "indices"
  input_dim: *code_book_dim
  shape: (32, 32)
  n_class: *code_book_size
  channel: 256
  kernel_size: 5
  n_block: 4
  n_res_block: 4
  res_channel: 256
  dropout: 0.1
  n_out_res_block: 0

entropy_top: &entropy_top !pretrained
  model: *entropy_top_template
  eval_mode: true
  freeze_model: true
  module_name: "_model._entropy_model._top_model"
  ckpt_path: *pretrained_top_path

entropy_model: &entropy_model !TopBottomPixelSNAIL
  top_model: *entropy_top
  bottom_model: *entropy_bottom
  # ignore: "top"

model: &model !VQVAE2CompressionModel
  vq_ae: *ae_model
  entropy_model: *entropy_model

# model: &model !VQVAE2CompressionModel
#   vq_ae: !pretrained
#     model: *ae_model
#     ckpt_path: *pretrained_ae_path
#     eval_mode: true
#     freeze_model: true
#     module_name: "_model"
#   entropy_model: *entropy_model

# Loss
# dist_loss: &dist_loss !MSEWrapLoss
# commit_loss: &commit_loss !CommitLoss
rate_loss: &rate_loss !CrossEntropyRateLoss

# loss: &loss !CompositeLoss
#   components: `[(dist_loss, 1.), (commit_loss, commit_weight)]`
loss: &loss !CompositeLoss
  components: `[(rate_loss, 1.)]`


### Lightning Module
pl_module: !LitAutoEncoderModule
  model: *model
  optimizer: !Adam
    lr: *lr
    params: `model._entropy_model.bottom_parameters()`
  loss: *loss
  sample_train: `train_dataset[0]`
  sample_val: `val_dataset[0]`
